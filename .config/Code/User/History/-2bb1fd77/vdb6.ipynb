{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 19:09:57.796608: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-10 19:09:57.835129: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-10 19:09:57.835168: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-10 19:09:57.836369: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-10 19:09:57.843323: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-10 19:09:58.472861: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# torch and torchvision imports\n",
    "\n",
    "import torch, torch.nn as nn, torch.optim as optim\n",
    "from torchmetrics.classification import MultilabelAUROC\n",
    "import numpy as np,  matplotlib.pyplot as plt, pandas as pd, pickle\n",
    "from torchinfo import summary\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from ResnetModel import *\n",
    "writer = SummaryWriter()\n",
    "# from google.colab import drive\n",
    "# drive.mount('/gdrive')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('/home/anirudhkailaje/Documents/01_UPenn/01_ESE5460/03_Project/ptb-xl-a-large-publicly-available-electrocardiography-dataset-1.0.1/Datasets/FormTrain.npz')['x']\n",
    "X_train = torch.from_numpy(np.transpose(X_train, (0, 2, 1))).float()\n",
    "y_train = np.load('/home/anirudhkailaje/Documents/01_UPenn/01_ESE5460/03_Project/ptb-xl-a-large-publicly-available-electrocardiography-dataset-1.0.1/Datasets/FormTrain.npz')['y']\n",
    "X_test = np.load('/home/anirudhkailaje/Documents/01_UPenn/01_ESE5460/03_Project/ptb-xl-a-large-publicly-available-electrocardiography-dataset-1.0.1/Datasets/FormVal.npz')['x']\n",
    "X_test = torch.from_numpy(np.transpose(X_test, (0, 2, 1))).float()\n",
    "y_test = np.load('/home/anirudhkailaje/Documents/01_UPenn/01_ESE5460/03_Project/ptb-xl-a-large-publicly-available-electrocardiography-dataset-1.0.1/Datasets/FormVal.npz')['y']\n",
    "y_train = torch.from_numpy(y_train).float()\n",
    "y_test = torch.from_numpy(y_test).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 12, 1000])\n"
     ]
    }
   ],
   "source": [
    "# X_train = torch.from_numpy(np.transpose(np.load('X_train.npy'), axes = (0,2,1))).float()\n",
    "# X_test = torch.from_numpy(np.transpose(np.load('X_test.npy'), axes = (0,2,1))).float()\n",
    "# y_train = pd.read_pickle('y_train.pickle').to_numpy()\n",
    "# y_test = pd.read_pickle('y_test.pickle').to_numpy()\n",
    "\n",
    "# class_list = []\n",
    "# for classes in y_train:\n",
    "#     class_list += classes \n",
    "# class_list = set(class_list)\n",
    "# class_list\n",
    "# diagSupclassDict = {val:i for i, val in enumerate(class_list)}\n",
    "# diagSupclassDict['Nodiag'] = 5\n",
    "# print(diagSupclassDict)\n",
    "\n",
    "# train_label_mapping = torch.zeros((X_train.shape[0], len(diagSupclassDict)))\n",
    "# print(f\"-\"*(1+30+5+35))\n",
    "# for i, classes in enumerate(y_train):\n",
    "#     for diagclass in classes:\n",
    "#         train_label_mapping[i, diagSupclassDict[diagclass]] = 1\n",
    "#     if len(classes) == 0:\n",
    "#         train_label_mapping[i, diagSupclassDict['Nodiag']] = 1\n",
    "    \n",
    "#     print(f\"|  {str(y_train[i]):>30}  |  {str(train_label_mapping[i]):<30}   |\")\n",
    "\n",
    "# test_label_mapping = torch.zeros((X_test.shape[0], len(diagSupclassDict)))\n",
    "# print(f\"-\"*(1+30+5+35))\n",
    "# for i, classes in enumerate(y_test):\n",
    "#     for diagclass in classes:\n",
    "#         test_label_mapping[i, diagSupclassDict[diagclass]] = 1\n",
    "#     if len(classes) == 0:\n",
    "#         test_label_mapping[i, diagSupclassDict['Nodiag']] = 1\n",
    "    \n",
    "#     print(f\"|  {str(y_train[i]):>30}  |  {str(test_label_mapping[i]):<30}   |\")\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "test_dataset = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "x = X_train[0:1]\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Resnet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2804, 19])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "ResNet                                   [1, 19]                   --\n",
      "├─Conv1d: 1-1                            [1, 64, 500]              5,376\n",
      "├─ReLU: 1-2                              [1, 64, 500]              --\n",
      "├─BatchNorm1d: 1-3                       [1, 64, 500]              128\n",
      "├─MaxPool1d: 1-4                         [1, 64, 250]              --\n",
      "├─Sequential: 1-5                        [1, 256, 250]             --\n",
      "│    └─Bottleneck: 2-1                   [1, 256, 250]             --\n",
      "│    │    └─Conv1d: 3-1                  [1, 64, 250]              4,096\n",
      "│    │    └─ReLU: 3-2                    [1, 64, 250]              --\n",
      "│    │    └─BatchNorm1d: 3-3             [1, 64, 250]              128\n",
      "│    │    └─Conv1d: 3-4                  [1, 64, 250]              12,288\n",
      "│    │    └─ReLU: 3-5                    [1, 64, 250]              --\n",
      "│    │    └─BatchNorm1d: 3-6             [1, 64, 250]              128\n",
      "│    │    └─Conv1d: 3-7                  [1, 256, 250]             16,384\n",
      "│    │    └─BatchNorm1d: 3-8             [1, 256, 250]             512\n",
      "│    │    └─Sequential: 3-9              [1, 256, 250]             16,896\n",
      "│    │    └─ReLU: 3-10                   [1, 256, 250]             --\n",
      "│    └─Bottleneck: 2-2                   [1, 256, 250]             --\n",
      "│    │    └─Conv1d: 3-11                 [1, 64, 250]              16,384\n",
      "│    │    └─ReLU: 3-12                   [1, 64, 250]              --\n",
      "│    │    └─BatchNorm1d: 3-13            [1, 64, 250]              128\n",
      "│    │    └─Conv1d: 3-14                 [1, 64, 250]              12,288\n",
      "│    │    └─ReLU: 3-15                   [1, 64, 250]              --\n",
      "│    │    └─BatchNorm1d: 3-16            [1, 64, 250]              128\n",
      "│    │    └─Conv1d: 3-17                 [1, 256, 250]             16,384\n",
      "│    │    └─BatchNorm1d: 3-18            [1, 256, 250]             512\n",
      "│    │    └─ReLU: 3-19                   [1, 256, 250]             --\n",
      "│    └─Bottleneck: 2-3                   [1, 256, 250]             --\n",
      "│    │    └─Conv1d: 3-20                 [1, 64, 250]              16,384\n",
      "│    │    └─ReLU: 3-21                   [1, 64, 250]              --\n",
      "│    │    └─BatchNorm1d: 3-22            [1, 64, 250]              128\n",
      "│    │    └─Conv1d: 3-23                 [1, 64, 250]              12,288\n",
      "│    │    └─ReLU: 3-24                   [1, 64, 250]              --\n",
      "│    │    └─BatchNorm1d: 3-25            [1, 64, 250]              128\n",
      "│    │    └─Conv1d: 3-26                 [1, 256, 250]             16,384\n",
      "│    │    └─BatchNorm1d: 3-27            [1, 256, 250]             512\n",
      "│    │    └─ReLU: 3-28                   [1, 256, 250]             --\n",
      "├─Sequential: 1-6                        [1, 512, 125]             --\n",
      "│    └─Bottleneck: 2-4                   [1, 512, 125]             --\n",
      "│    │    └─Conv1d: 3-29                 [1, 128, 250]             32,768\n",
      "│    │    └─ReLU: 3-30                   [1, 128, 250]             --\n",
      "│    │    └─BatchNorm1d: 3-31            [1, 128, 250]             256\n",
      "│    │    └─Conv1d: 3-32                 [1, 128, 125]             49,152\n",
      "│    │    └─ReLU: 3-33                   [1, 128, 125]             --\n",
      "│    │    └─BatchNorm1d: 3-34            [1, 128, 125]             256\n",
      "│    │    └─Conv1d: 3-35                 [1, 512, 125]             65,536\n",
      "│    │    └─BatchNorm1d: 3-36            [1, 512, 125]             1,024\n",
      "│    │    └─Sequential: 3-37             [1, 512, 125]             132,096\n",
      "│    │    └─ReLU: 3-38                   [1, 512, 125]             --\n",
      "│    └─Bottleneck: 2-5                   [1, 512, 125]             --\n",
      "│    │    └─Conv1d: 3-39                 [1, 128, 125]             65,536\n",
      "│    │    └─ReLU: 3-40                   [1, 128, 125]             --\n",
      "│    │    └─BatchNorm1d: 3-41            [1, 128, 125]             256\n",
      "│    │    └─Conv1d: 3-42                 [1, 128, 125]             49,152\n",
      "│    │    └─ReLU: 3-43                   [1, 128, 125]             --\n",
      "│    │    └─BatchNorm1d: 3-44            [1, 128, 125]             256\n",
      "│    │    └─Conv1d: 3-45                 [1, 512, 125]             65,536\n",
      "│    │    └─BatchNorm1d: 3-46            [1, 512, 125]             1,024\n",
      "│    │    └─ReLU: 3-47                   [1, 512, 125]             --\n",
      "│    └─Bottleneck: 2-6                   [1, 512, 125]             --\n",
      "│    │    └─Conv1d: 3-48                 [1, 128, 125]             65,536\n",
      "│    │    └─ReLU: 3-49                   [1, 128, 125]             --\n",
      "│    │    └─BatchNorm1d: 3-50            [1, 128, 125]             256\n",
      "│    │    └─Conv1d: 3-51                 [1, 128, 125]             49,152\n",
      "│    │    └─ReLU: 3-52                   [1, 128, 125]             --\n",
      "│    │    └─BatchNorm1d: 3-53            [1, 128, 125]             256\n",
      "│    │    └─Conv1d: 3-54                 [1, 512, 125]             65,536\n",
      "│    │    └─BatchNorm1d: 3-55            [1, 512, 125]             1,024\n",
      "│    │    └─ReLU: 3-56                   [1, 512, 125]             --\n",
      "│    └─Bottleneck: 2-7                   [1, 512, 125]             --\n",
      "│    │    └─Conv1d: 3-57                 [1, 128, 125]             65,536\n",
      "│    │    └─ReLU: 3-58                   [1, 128, 125]             --\n",
      "│    │    └─BatchNorm1d: 3-59            [1, 128, 125]             256\n",
      "│    │    └─Conv1d: 3-60                 [1, 128, 125]             49,152\n",
      "│    │    └─ReLU: 3-61                   [1, 128, 125]             --\n",
      "│    │    └─BatchNorm1d: 3-62            [1, 128, 125]             256\n",
      "│    │    └─Conv1d: 3-63                 [1, 512, 125]             65,536\n",
      "│    │    └─BatchNorm1d: 3-64            [1, 512, 125]             1,024\n",
      "│    │    └─ReLU: 3-65                   [1, 512, 125]             --\n",
      "├─Sequential: 1-7                        [1, 1024, 63]             --\n",
      "│    └─Bottleneck: 2-8                   [1, 1024, 63]             --\n",
      "│    │    └─Conv1d: 3-66                 [1, 256, 125]             131,072\n",
      "│    │    └─ReLU: 3-67                   [1, 256, 125]             --\n",
      "│    │    └─BatchNorm1d: 3-68            [1, 256, 125]             512\n",
      "│    │    └─Conv1d: 3-69                 [1, 256, 63]              196,608\n",
      "│    │    └─ReLU: 3-70                   [1, 256, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-71            [1, 256, 63]              512\n",
      "│    │    └─Conv1d: 3-72                 [1, 1024, 63]             262,144\n",
      "│    │    └─BatchNorm1d: 3-73            [1, 1024, 63]             2,048\n",
      "│    │    └─Sequential: 3-74             [1, 1024, 63]             526,336\n",
      "│    │    └─ReLU: 3-75                   [1, 1024, 63]             --\n",
      "│    └─Bottleneck: 2-9                   [1, 1024, 63]             --\n",
      "│    │    └─Conv1d: 3-76                 [1, 256, 63]              262,144\n",
      "│    │    └─ReLU: 3-77                   [1, 256, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-78            [1, 256, 63]              512\n",
      "│    │    └─Conv1d: 3-79                 [1, 256, 63]              196,608\n",
      "│    │    └─ReLU: 3-80                   [1, 256, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-81            [1, 256, 63]              512\n",
      "│    │    └─Conv1d: 3-82                 [1, 1024, 63]             262,144\n",
      "│    │    └─BatchNorm1d: 3-83            [1, 1024, 63]             2,048\n",
      "│    │    └─ReLU: 3-84                   [1, 1024, 63]             --\n",
      "│    └─Bottleneck: 2-10                  [1, 1024, 63]             --\n",
      "│    │    └─Conv1d: 3-85                 [1, 256, 63]              262,144\n",
      "│    │    └─ReLU: 3-86                   [1, 256, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-87            [1, 256, 63]              512\n",
      "│    │    └─Conv1d: 3-88                 [1, 256, 63]              196,608\n",
      "│    │    └─ReLU: 3-89                   [1, 256, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-90            [1, 256, 63]              512\n",
      "│    │    └─Conv1d: 3-91                 [1, 1024, 63]             262,144\n",
      "│    │    └─BatchNorm1d: 3-92            [1, 1024, 63]             2,048\n",
      "│    │    └─ReLU: 3-93                   [1, 1024, 63]             --\n",
      "│    └─Bottleneck: 2-11                  [1, 1024, 63]             --\n",
      "│    │    └─Conv1d: 3-94                 [1, 256, 63]              262,144\n",
      "│    │    └─ReLU: 3-95                   [1, 256, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-96            [1, 256, 63]              512\n",
      "│    │    └─Conv1d: 3-97                 [1, 256, 63]              196,608\n",
      "│    │    └─ReLU: 3-98                   [1, 256, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-99            [1, 256, 63]              512\n",
      "│    │    └─Conv1d: 3-100                [1, 1024, 63]             262,144\n",
      "│    │    └─BatchNorm1d: 3-101           [1, 1024, 63]             2,048\n",
      "│    │    └─ReLU: 3-102                  [1, 1024, 63]             --\n",
      "│    └─Bottleneck: 2-12                  [1, 1024, 63]             --\n",
      "│    │    └─Conv1d: 3-103                [1, 256, 63]              262,144\n",
      "│    │    └─ReLU: 3-104                  [1, 256, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-105           [1, 256, 63]              512\n",
      "│    │    └─Conv1d: 3-106                [1, 256, 63]              196,608\n",
      "│    │    └─ReLU: 3-107                  [1, 256, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-108           [1, 256, 63]              512\n",
      "│    │    └─Conv1d: 3-109                [1, 1024, 63]             262,144\n",
      "│    │    └─BatchNorm1d: 3-110           [1, 1024, 63]             2,048\n",
      "│    │    └─ReLU: 3-111                  [1, 1024, 63]             --\n",
      "│    └─Bottleneck: 2-13                  [1, 1024, 63]             --\n",
      "│    │    └─Conv1d: 3-112                [1, 256, 63]              262,144\n",
      "│    │    └─ReLU: 3-113                  [1, 256, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-114           [1, 256, 63]              512\n",
      "│    │    └─Conv1d: 3-115                [1, 256, 63]              196,608\n",
      "│    │    └─ReLU: 3-116                  [1, 256, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-117           [1, 256, 63]              512\n",
      "│    │    └─Conv1d: 3-118                [1, 1024, 63]             262,144\n",
      "│    │    └─BatchNorm1d: 3-119           [1, 1024, 63]             2,048\n",
      "│    │    └─ReLU: 3-120                  [1, 1024, 63]             --\n",
      "│    └─Bottleneck: 2-14                  [1, 1024, 63]             --\n",
      "│    │    └─Conv1d: 3-121                [1, 256, 63]              262,144\n",
      "│    │    └─ReLU: 3-122                  [1, 256, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-123           [1, 256, 63]              512\n",
      "│    │    └─Conv1d: 3-124                [1, 256, 63]              196,608\n",
      "│    │    └─ReLU: 3-125                  [1, 256, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-126           [1, 256, 63]              512\n",
      "│    │    └─Conv1d: 3-127                [1, 1024, 63]             262,144\n",
      "│    │    └─BatchNorm1d: 3-128           [1, 1024, 63]             2,048\n",
      "│    │    └─ReLU: 3-129                  [1, 1024, 63]             --\n",
      "│    └─Bottleneck: 2-15                  [1, 1024, 63]             --\n",
      "│    │    └─Conv1d: 3-130                [1, 256, 63]              262,144\n",
      "│    │    └─ReLU: 3-131                  [1, 256, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-132           [1, 256, 63]              512\n",
      "│    │    └─Conv1d: 3-133                [1, 256, 63]              196,608\n",
      "│    │    └─ReLU: 3-134                  [1, 256, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-135           [1, 256, 63]              512\n",
      "│    │    └─Conv1d: 3-136                [1, 1024, 63]             262,144\n",
      "│    │    └─BatchNorm1d: 3-137           [1, 1024, 63]             2,048\n",
      "│    │    └─ReLU: 3-138                  [1, 1024, 63]             --\n",
      "│    └─Bottleneck: 2-16                  [1, 1024, 63]             --\n",
      "│    │    └─Conv1d: 3-139                [1, 256, 63]              262,144\n",
      "│    │    └─ReLU: 3-140                  [1, 256, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-141           [1, 256, 63]              512\n",
      "│    │    └─Conv1d: 3-142                [1, 256, 63]              196,608\n",
      "│    │    └─ReLU: 3-143                  [1, 256, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-144           [1, 256, 63]              512\n",
      "│    │    └─Conv1d: 3-145                [1, 1024, 63]             262,144\n",
      "│    │    └─BatchNorm1d: 3-146           [1, 1024, 63]             2,048\n",
      "│    │    └─ReLU: 3-147                  [1, 1024, 63]             --\n",
      "│    └─Bottleneck: 2-17                  [1, 1024, 63]             --\n",
      "│    │    └─Conv1d: 3-148                [1, 256, 63]              262,144\n",
      "│    │    └─ReLU: 3-149                  [1, 256, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-150           [1, 256, 63]              512\n",
      "│    │    └─Conv1d: 3-151                [1, 256, 63]              196,608\n",
      "│    │    └─ReLU: 3-152                  [1, 256, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-153           [1, 256, 63]              512\n",
      "│    │    └─Conv1d: 3-154                [1, 1024, 63]             262,144\n",
      "│    │    └─BatchNorm1d: 3-155           [1, 1024, 63]             2,048\n",
      "│    │    └─ReLU: 3-156                  [1, 1024, 63]             --\n",
      "│    └─Bottleneck: 2-18                  [1, 1024, 63]             --\n",
      "│    │    └─Conv1d: 3-157                [1, 256, 63]              262,144\n",
      "│    │    └─ReLU: 3-158                  [1, 256, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-159           [1, 256, 63]              512\n",
      "│    │    └─Conv1d: 3-160                [1, 256, 63]              196,608\n",
      "│    │    └─ReLU: 3-161                  [1, 256, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-162           [1, 256, 63]              512\n",
      "│    │    └─Conv1d: 3-163                [1, 1024, 63]             262,144\n",
      "│    │    └─BatchNorm1d: 3-164           [1, 1024, 63]             2,048\n",
      "│    │    └─ReLU: 3-165                  [1, 1024, 63]             --\n",
      "│    └─Bottleneck: 2-19                  [1, 1024, 63]             --\n",
      "│    │    └─Conv1d: 3-166                [1, 256, 63]              262,144\n",
      "│    │    └─ReLU: 3-167                  [1, 256, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-168           [1, 256, 63]              512\n",
      "│    │    └─Conv1d: 3-169                [1, 256, 63]              196,608\n",
      "│    │    └─ReLU: 3-170                  [1, 256, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-171           [1, 256, 63]              512\n",
      "│    │    └─Conv1d: 3-172                [1, 1024, 63]             262,144\n",
      "│    │    └─BatchNorm1d: 3-173           [1, 1024, 63]             2,048\n",
      "│    │    └─ReLU: 3-174                  [1, 1024, 63]             --\n",
      "│    └─Bottleneck: 2-20                  [1, 1024, 63]             --\n",
      "│    │    └─Conv1d: 3-175                [1, 256, 63]              262,144\n",
      "│    │    └─ReLU: 3-176                  [1, 256, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-177           [1, 256, 63]              512\n",
      "│    │    └─Conv1d: 3-178                [1, 256, 63]              196,608\n",
      "│    │    └─ReLU: 3-179                  [1, 256, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-180           [1, 256, 63]              512\n",
      "│    │    └─Conv1d: 3-181                [1, 1024, 63]             262,144\n",
      "│    │    └─BatchNorm1d: 3-182           [1, 1024, 63]             2,048\n",
      "│    │    └─ReLU: 3-183                  [1, 1024, 63]             --\n",
      "│    └─Bottleneck: 2-21                  [1, 1024, 63]             --\n",
      "│    │    └─Conv1d: 3-184                [1, 256, 63]              262,144\n",
      "│    │    └─ReLU: 3-185                  [1, 256, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-186           [1, 256, 63]              512\n",
      "│    │    └─Conv1d: 3-187                [1, 256, 63]              196,608\n",
      "│    │    └─ReLU: 3-188                  [1, 256, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-189           [1, 256, 63]              512\n",
      "│    │    └─Conv1d: 3-190                [1, 1024, 63]             262,144\n",
      "│    │    └─BatchNorm1d: 3-191           [1, 1024, 63]             2,048\n",
      "│    │    └─ReLU: 3-192                  [1, 1024, 63]             --\n",
      "│    └─Bottleneck: 2-22                  [1, 1024, 63]             --\n",
      "│    │    └─Conv1d: 3-193                [1, 256, 63]              262,144\n",
      "│    │    └─ReLU: 3-194                  [1, 256, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-195           [1, 256, 63]              512\n",
      "│    │    └─Conv1d: 3-196                [1, 256, 63]              196,608\n",
      "│    │    └─ReLU: 3-197                  [1, 256, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-198           [1, 256, 63]              512\n",
      "│    │    └─Conv1d: 3-199                [1, 1024, 63]             262,144\n",
      "│    │    └─BatchNorm1d: 3-200           [1, 1024, 63]             2,048\n",
      "│    │    └─ReLU: 3-201                  [1, 1024, 63]             --\n",
      "│    └─Bottleneck: 2-23                  [1, 1024, 63]             --\n",
      "│    │    └─Conv1d: 3-202                [1, 256, 63]              262,144\n",
      "│    │    └─ReLU: 3-203                  [1, 256, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-204           [1, 256, 63]              512\n",
      "│    │    └─Conv1d: 3-205                [1, 256, 63]              196,608\n",
      "│    │    └─ReLU: 3-206                  [1, 256, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-207           [1, 256, 63]              512\n",
      "│    │    └─Conv1d: 3-208                [1, 1024, 63]             262,144\n",
      "│    │    └─BatchNorm1d: 3-209           [1, 1024, 63]             2,048\n",
      "│    │    └─ReLU: 3-210                  [1, 1024, 63]             --\n",
      "│    └─Bottleneck: 2-24                  [1, 1024, 63]             --\n",
      "│    │    └─Conv1d: 3-211                [1, 256, 63]              262,144\n",
      "│    │    └─ReLU: 3-212                  [1, 256, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-213           [1, 256, 63]              512\n",
      "│    │    └─Conv1d: 3-214                [1, 256, 63]              196,608\n",
      "│    │    └─ReLU: 3-215                  [1, 256, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-216           [1, 256, 63]              512\n",
      "│    │    └─Conv1d: 3-217                [1, 1024, 63]             262,144\n",
      "│    │    └─BatchNorm1d: 3-218           [1, 1024, 63]             2,048\n",
      "│    │    └─ReLU: 3-219                  [1, 1024, 63]             --\n",
      "│    └─Bottleneck: 2-25                  [1, 1024, 63]             --\n",
      "│    │    └─Conv1d: 3-220                [1, 256, 63]              262,144\n",
      "│    │    └─ReLU: 3-221                  [1, 256, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-222           [1, 256, 63]              512\n",
      "│    │    └─Conv1d: 3-223                [1, 256, 63]              196,608\n",
      "│    │    └─ReLU: 3-224                  [1, 256, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-225           [1, 256, 63]              512\n",
      "│    │    └─Conv1d: 3-226                [1, 1024, 63]             262,144\n",
      "│    │    └─BatchNorm1d: 3-227           [1, 1024, 63]             2,048\n",
      "│    │    └─ReLU: 3-228                  [1, 1024, 63]             --\n",
      "│    └─Bottleneck: 2-26                  [1, 1024, 63]             --\n",
      "│    │    └─Conv1d: 3-229                [1, 256, 63]              262,144\n",
      "│    │    └─ReLU: 3-230                  [1, 256, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-231           [1, 256, 63]              512\n",
      "│    │    └─Conv1d: 3-232                [1, 256, 63]              196,608\n",
      "│    │    └─ReLU: 3-233                  [1, 256, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-234           [1, 256, 63]              512\n",
      "│    │    └─Conv1d: 3-235                [1, 1024, 63]             262,144\n",
      "│    │    └─BatchNorm1d: 3-236           [1, 1024, 63]             2,048\n",
      "│    │    └─ReLU: 3-237                  [1, 1024, 63]             --\n",
      "│    └─Bottleneck: 2-27                  [1, 1024, 63]             --\n",
      "│    │    └─Conv1d: 3-238                [1, 256, 63]              262,144\n",
      "│    │    └─ReLU: 3-239                  [1, 256, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-240           [1, 256, 63]              512\n",
      "│    │    └─Conv1d: 3-241                [1, 256, 63]              196,608\n",
      "│    │    └─ReLU: 3-242                  [1, 256, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-243           [1, 256, 63]              512\n",
      "│    │    └─Conv1d: 3-244                [1, 1024, 63]             262,144\n",
      "│    │    └─BatchNorm1d: 3-245           [1, 1024, 63]             2,048\n",
      "│    │    └─ReLU: 3-246                  [1, 1024, 63]             --\n",
      "│    └─Bottleneck: 2-28                  [1, 1024, 63]             --\n",
      "│    │    └─Conv1d: 3-247                [1, 256, 63]              262,144\n",
      "│    │    └─ReLU: 3-248                  [1, 256, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-249           [1, 256, 63]              512\n",
      "│    │    └─Conv1d: 3-250                [1, 256, 63]              196,608\n",
      "│    │    └─ReLU: 3-251                  [1, 256, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-252           [1, 256, 63]              512\n",
      "│    │    └─Conv1d: 3-253                [1, 1024, 63]             262,144\n",
      "│    │    └─BatchNorm1d: 3-254           [1, 1024, 63]             2,048\n",
      "│    │    └─ReLU: 3-255                  [1, 1024, 63]             --\n",
      "│    └─Bottleneck: 2-29                  [1, 1024, 63]             --\n",
      "│    │    └─Conv1d: 3-256                [1, 256, 63]              262,144\n",
      "│    │    └─ReLU: 3-257                  [1, 256, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-258           [1, 256, 63]              512\n",
      "│    │    └─Conv1d: 3-259                [1, 256, 63]              196,608\n",
      "│    │    └─ReLU: 3-260                  [1, 256, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-261           [1, 256, 63]              512\n",
      "│    │    └─Conv1d: 3-262                [1, 1024, 63]             262,144\n",
      "│    │    └─BatchNorm1d: 3-263           [1, 1024, 63]             2,048\n",
      "│    │    └─ReLU: 3-264                  [1, 1024, 63]             --\n",
      "│    └─Bottleneck: 2-30                  [1, 1024, 63]             --\n",
      "│    │    └─Conv1d: 3-265                [1, 256, 63]              262,144\n",
      "│    │    └─ReLU: 3-266                  [1, 256, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-267           [1, 256, 63]              512\n",
      "│    │    └─Conv1d: 3-268                [1, 256, 63]              196,608\n",
      "│    │    └─ReLU: 3-269                  [1, 256, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-270           [1, 256, 63]              512\n",
      "│    │    └─Conv1d: 3-271                [1, 1024, 63]             262,144\n",
      "│    │    └─BatchNorm1d: 3-272           [1, 1024, 63]             2,048\n",
      "│    │    └─ReLU: 3-273                  [1, 1024, 63]             --\n",
      "├─Sequential: 1-8                        [1, 2048, 32]             --\n",
      "│    └─Bottleneck: 2-31                  [1, 2048, 32]             --\n",
      "│    │    └─Conv1d: 3-274                [1, 512, 63]              524,288\n",
      "│    │    └─ReLU: 3-275                  [1, 512, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-276           [1, 512, 63]              1,024\n",
      "│    │    └─Conv1d: 3-277                [1, 512, 32]              786,432\n",
      "│    │    └─ReLU: 3-278                  [1, 512, 32]              --\n",
      "│    │    └─BatchNorm1d: 3-279           [1, 512, 32]              1,024\n",
      "│    │    └─Conv1d: 3-280                [1, 2048, 32]             1,048,576\n",
      "│    │    └─BatchNorm1d: 3-281           [1, 2048, 32]             4,096\n",
      "│    │    └─Sequential: 3-282            [1, 2048, 32]             2,101,248\n",
      "│    │    └─ReLU: 3-283                  [1, 2048, 32]             --\n",
      "│    └─Bottleneck: 2-32                  [1, 2048, 32]             --\n",
      "│    │    └─Conv1d: 3-284                [1, 512, 32]              1,048,576\n",
      "│    │    └─ReLU: 3-285                  [1, 512, 32]              --\n",
      "│    │    └─BatchNorm1d: 3-286           [1, 512, 32]              1,024\n",
      "│    │    └─Conv1d: 3-287                [1, 512, 32]              786,432\n",
      "│    │    └─ReLU: 3-288                  [1, 512, 32]              --\n",
      "│    │    └─BatchNorm1d: 3-289           [1, 512, 32]              1,024\n",
      "│    │    └─Conv1d: 3-290                [1, 2048, 32]             1,048,576\n",
      "│    │    └─BatchNorm1d: 3-291           [1, 2048, 32]             4,096\n",
      "│    │    └─ReLU: 3-292                  [1, 2048, 32]             --\n",
      "│    └─Bottleneck: 2-33                  [1, 2048, 32]             --\n",
      "│    │    └─Conv1d: 3-293                [1, 512, 32]              1,048,576\n",
      "│    │    └─ReLU: 3-294                  [1, 512, 32]              --\n",
      "│    │    └─BatchNorm1d: 3-295           [1, 512, 32]              1,024\n",
      "│    │    └─Conv1d: 3-296                [1, 512, 32]              786,432\n",
      "│    │    └─ReLU: 3-297                  [1, 512, 32]              --\n",
      "│    │    └─BatchNorm1d: 3-298           [1, 512, 32]              1,024\n",
      "│    │    └─Conv1d: 3-299                [1, 2048, 32]             1,048,576\n",
      "│    │    └─BatchNorm1d: 3-300           [1, 2048, 32]             4,096\n",
      "│    │    └─ReLU: 3-301                  [1, 2048, 32]             --\n",
      "├─AdaptiveAvgPool1d: 1-9                 [1, 2048, 1]              --\n",
      "├─Linear: 1-10                           [1, 19]                   38,931\n",
      "├─Sigmoid: 1-11                          [1, 19]                   --\n",
      "==========================================================================================\n",
      "Total params: 28,305,555\n",
      "Trainable params: 28,305,555\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (Units.GIGABYTES): 1.57\n",
      "==========================================================================================\n",
      "Input size (MB): 0.05\n",
      "Forward/backward pass size (MB): 56.49\n",
      "Params size (MB): 113.22\n",
      "Estimated Total Size (MB): 169.76\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "model = ResNet(Bottleneck, [3, 4, 23, 3], num_classes=19).float()\n",
    "print(summary(model.to(device), (1,12,1000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(4*1024-107.88)/107.88 #Max batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = 64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Test AUC metric\"\"\"\n",
    "ml_auroc = MultilabelAUROC(num_labels=y_train.shape[1], average=\"macro\", thresholds=None)\n",
    "# ml_auroc(model(X_train[0:10].to(device)), train_label_mapping[0:10].to(device).int())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Max Learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "epochs = 10\n",
    "model = model = ResNet(Bottleneck, [3, 4, 23, 3], num_classes=19).float()\n",
    "model = model.to(device)\n",
    "lr = 1e-6\n",
    "optimizer = optim.Adam(model.parameters(), lr = lr, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = []\n",
    "lrs = []\n",
    "\n",
    "for i, (signal, labels) in enumerate(train_loader):\n",
    "    signal = signal.to(device)\n",
    "    labels = labels.to(device)\n",
    "    output = model(signal)\n",
    "    loss = criterion(output, labels)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    train_loss.append(loss.item())\n",
    "    lrs.append(lr)\n",
    "    lr *= 1.1\n",
    "\n",
    "    for g in optimizer.param_groups:\n",
    "        g['lr'] = lr \n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    if i > 200 or lr > 1:\n",
    "        break\n",
    "\n",
    "lrs = np.array(lrs)\n",
    "train_loss = np.array(train_loss)\n",
    "\n",
    "lr_max = lrs[np.where(train_loss == train_loss.min())[0]]\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(lrs, train_loss)\n",
    "plt.plot(lr_max, train_loss[lrs == lr_max], '.r')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "fig = plt.figure()\n",
    "plt.plot(lrs, train_loss)\n",
    "plt.plot(lr_max, train_loss[lrs == lr_max], '.r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_max = 0.135/10\n",
    "lr = lr_max\n",
    "epochs = 10\n",
    "criterion = nn.BCELoss()\n",
    "epochs = 10\n",
    "model = model = ResNet(Bottleneck, [3, 4, 23, 3], num_classes=19).float()\n",
    "model = model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr = lr, weight_decay=1e-4)\n",
    "\n",
    "for g in optimizer.param_groups:\n",
    "    g['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs = []\n",
    "t = 0\n",
    "steps_per_epoch = len(train_loader)\n",
    "T_max = steps_per_epoch*epochs\n",
    "T_0 = T_max/5 \n",
    "for t in range(T_max):\n",
    "    if t <= T_0:\n",
    "        lr = 10**(-4) + (t/T_0)*lr_max  \n",
    "    else: \n",
    "        lr = lr_max*np.cos((np.pi/2)*((t-T_0)/(T_max-T_0))) + 10**(-6)\n",
    "    lrs.append(lr)\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(lrs)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr =lr_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0\n",
    "steps_per_epoch = len(train_loader)\n",
    "T_max = steps_per_epoch*epochs\n",
    "T_0 = T_max/5 \n",
    "learning_rates = []\n",
    "train_losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i, (signal, labels) in enumerate(train_loader):\n",
    "        signal = signal.to(device); labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(signal)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
    "        if t <= T_0:\n",
    "            lr = 10**(-4) + (t/T_0)*lr_max  \n",
    "        else: \n",
    "            lr = lr_max*np.cos((np.pi/2)*((t-T_0)/(T_max-T_0))) + 10**(-6) \n",
    "\n",
    "        for g in optimizer.param_groups:\n",
    "            g['lr'] = lr \n",
    "        learning_rates.append(lr)\n",
    "        train_losses.append(loss.item())\n",
    "        optimizer.step()\n",
    "        t+=1\n",
    "        \n",
    "        train_AUC = ml_auroc(outputs, labels.int())\n",
    "        writer.add_scalar(\"Train_Loss\", loss, t)\n",
    "        writer.add_scalar(\"Learning rate\", lr, t)\n",
    "        writer.add_scalar(\"Batch Train AUC\", train_AUC, t)\n",
    "\n",
    "        if i%100 == 0:\n",
    "            print(f\"Step: {i+1}/{len(train_loader)}  |  Train loss: {loss.item():.4f}  |  Train AUC: {train_AUC:.4f}\")\n",
    "           \n",
    "\n",
    "    # model.eval()\n",
    "    test_auc = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (signal, labels) in enumerate(test_loader):\n",
    "            signal = signal.to(device); labels = labels.to(device)\n",
    "            outputs = model(signal)\n",
    "            test_auc += ml_auroc(outputs, labels.int())\n",
    "        test_auc /= len(test_loader)\n",
    "    writer.add_scalar(\"Test AUC\", test_auc, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_Auc = 0\n",
    "with torch.no_grad():\n",
    "    for i, (signal, labels) in enumerate(test_loader):\n",
    "        signal = signal.to(device); labels = labels.to(device)\n",
    "        outputs = model(signal)\n",
    "        test_Auc += ml_auroc(outputs, labels.int())\n",
    "\n",
    "test_Auc /= len(test_loader)\n",
    "test_Auc\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('resnet101_model.pickle', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, max_len=1000, emb_size=12):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "\n",
    "        pe = torch.zeros(max_len, emb_size)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, emb_size, 2).float() * (-np.log(10000.0) / emb_size))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:x.size(0), :]\n",
    "\n",
    "class Transformer(nn.Transformer):\n",
    "    def __init__(self, emb_size=12, nhead=6, depth=6, hidden_size=128, seq_length=1000, num_classes=5):\n",
    "        super(Transformer, self).__init__(d_model=emb_size, nhead=nhead, num_encoder_layers=depth, num_decoder_layers=depth, dim_feedforward=hidden_size)\n",
    "    \n",
    "        self.pos_encoder = PositionalEncoding(seq_length, emb_size)\n",
    "        self.decoder = nn.Linear(emb_size, 256)\n",
    "        self.linear1 = nn.Linear(256, 512)\n",
    "        self.linear2 = nn.Linear(512, 1024)\n",
    "        self.linear3 = nn.Linear(1024, num_classes)\n",
    "        \n",
    "    def __forward_impl(self, x):\n",
    "        #x = self.pos_encoder(x)\n",
    "        x = self.encoder(x)\n",
    "        x = x.mean(dim=1)\n",
    "        x = self.decoder(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.linear1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.linear3(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.__forward_impl(x)\n",
    "    \n",
    "model = Transformer(nhead=6, hidden_size=512, depth=3).to(device)\n",
    "\n",
    "model(X_train[0].T.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0].T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer(nhead=6, hidden_size=512, depth=3).to(device)\n",
    "print(summary(model, [1000, 12]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model.to(device), (1,1000, 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "512*1024+512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Transformer needs X input as (seq_len, batch_size, channels)\"\"\"\n",
    "model = Transformer(nhead=6, hidden_size=512, depth=3).to(device)\n",
    "# resnetModel = ResNet(Bottleneck, [3, 4, 23, 3], num_classes=6).to(device)\n",
    "\n",
    "# resnetModel(X_train[0:1].to(device))\n",
    "print(\"Forward pass\")\n",
    "X_train = X_train.transpose(0,1).transpose(0,2)\n",
    "model(X_train[:, :17, :].to(device))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
