{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-10 19:09:57.796608: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-10 19:09:57.835129: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-10 19:09:57.835168: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-10 19:09:57.836369: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-10 19:09:57.843323: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-10 19:09:58.472861: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# torch and torchvision imports\n",
    "\n",
    "import torch, torch.nn as nn, torch.optim as optim\n",
    "from torchmetrics.classification import MultilabelAUROC\n",
    "import numpy as np,  matplotlib.pyplot as plt, pandas as pd, pickle\n",
    "from torchinfo import summary\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from ResnetModel import *\n",
    "writer = SummaryWriter()\n",
    "# from google.colab import drive\n",
    "# drive.mount('/gdrive')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load('/home/anirudhkailaje/Documents/01_UPenn/01_ESE5460/03_Project/ptb-xl-a-large-publicly-available-electrocardiography-dataset-1.0.1/Datasets/FormTrain.npz')['x']\n",
    "X_train = torch.from_numpy(np.transpose(X_train, (0, 2, 1))).float()\n",
    "y_train = np.load('/home/anirudhkailaje/Documents/01_UPenn/01_ESE5460/03_Project/ptb-xl-a-large-publicly-available-electrocardiography-dataset-1.0.1/Datasets/FormTrain.npz')['y']\n",
    "X_test = np.load('/home/anirudhkailaje/Documents/01_UPenn/01_ESE5460/03_Project/ptb-xl-a-large-publicly-available-electrocardiography-dataset-1.0.1/Datasets/FormVal.npz')['x']\n",
    "X_test = torch.from_numpy(np.transpose(X_test, (0, 2, 1))).float()\n",
    "y_test = np.load('/home/anirudhkailaje/Documents/01_UPenn/01_ESE5460/03_Project/ptb-xl-a-large-publicly-available-electrocardiography-dataset-1.0.1/Datasets/FormVal.npz')['y']\n",
    "y_train = torch.from_numpy(y_train).float()\n",
    "y_test = torch.from_numpy(y_test).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 12, 1000])\n"
     ]
    }
   ],
   "source": [
    "# X_train = torch.from_numpy(np.transpose(np.load('X_train.npy'), axes = (0,2,1))).float()\n",
    "# X_test = torch.from_numpy(np.transpose(np.load('X_test.npy'), axes = (0,2,1))).float()\n",
    "# y_train = pd.read_pickle('y_train.pickle').to_numpy()\n",
    "# y_test = pd.read_pickle('y_test.pickle').to_numpy()\n",
    "\n",
    "# class_list = []\n",
    "# for classes in y_train:\n",
    "#     class_list += classes \n",
    "# class_list = set(class_list)\n",
    "# class_list\n",
    "# diagSupclassDict = {val:i for i, val in enumerate(class_list)}\n",
    "# diagSupclassDict['Nodiag'] = 5\n",
    "# print(diagSupclassDict)\n",
    "\n",
    "# train_label_mapping = torch.zeros((X_train.shape[0], len(diagSupclassDict)))\n",
    "# print(f\"-\"*(1+30+5+35))\n",
    "# for i, classes in enumerate(y_train):\n",
    "#     for diagclass in classes:\n",
    "#         train_label_mapping[i, diagSupclassDict[diagclass]] = 1\n",
    "#     if len(classes) == 0:\n",
    "#         train_label_mapping[i, diagSupclassDict['Nodiag']] = 1\n",
    "    \n",
    "#     print(f\"|  {str(y_train[i]):>30}  |  {str(train_label_mapping[i]):<30}   |\")\n",
    "\n",
    "# test_label_mapping = torch.zeros((X_test.shape[0], len(diagSupclassDict)))\n",
    "# print(f\"-\"*(1+30+5+35))\n",
    "# for i, classes in enumerate(y_test):\n",
    "#     for diagclass in classes:\n",
    "#         test_label_mapping[i, diagSupclassDict[diagclass]] = 1\n",
    "#     if len(classes) == 0:\n",
    "#         test_label_mapping[i, diagSupclassDict['Nodiag']] = 1\n",
    "    \n",
    "#     print(f\"|  {str(y_train[i]):>30}  |  {str(test_label_mapping[i]):<30}   |\")\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "test_dataset = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "x = X_train[0:1]\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Resnet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2804, 19])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "ResNet                                   [1, 19]                   --\n",
      "├─Conv1d: 1-1                            [1, 64, 500]              5,376\n",
      "├─ReLU: 1-2                              [1, 64, 500]              --\n",
      "├─BatchNorm1d: 1-3                       [1, 64, 500]              128\n",
      "├─MaxPool1d: 1-4                         [1, 64, 250]              --\n",
      "├─Sequential: 1-5                        [1, 256, 250]             --\n",
      "│    └─Bottleneck: 2-1                   [1, 256, 250]             --\n",
      "│    │    └─Conv1d: 3-1                  [1, 64, 250]              4,096\n",
      "│    │    └─ReLU: 3-2                    [1, 64, 250]              --\n",
      "│    │    └─BatchNorm1d: 3-3             [1, 64, 250]              128\n",
      "│    │    └─Conv1d: 3-4                  [1, 64, 250]              12,288\n",
      "│    │    └─ReLU: 3-5                    [1, 64, 250]              --\n",
      "│    │    └─BatchNorm1d: 3-6             [1, 64, 250]              128\n",
      "│    │    └─Conv1d: 3-7                  [1, 256, 250]             16,384\n",
      "│    │    └─BatchNorm1d: 3-8             [1, 256, 250]             512\n",
      "│    │    └─Sequential: 3-9              [1, 256, 250]             16,896\n",
      "│    │    └─ReLU: 3-10                   [1, 256, 250]             --\n",
      "│    └─Bottleneck: 2-2                   [1, 256, 250]             --\n",
      "│    │    └─Conv1d: 3-11                 [1, 64, 250]              16,384\n",
      "│    │    └─ReLU: 3-12                   [1, 64, 250]              --\n",
      "│    │    └─BatchNorm1d: 3-13            [1, 64, 250]              128\n",
      "│    │    └─Conv1d: 3-14                 [1, 64, 250]              12,288\n",
      "│    │    └─ReLU: 3-15                   [1, 64, 250]              --\n",
      "│    │    └─BatchNorm1d: 3-16            [1, 64, 250]              128\n",
      "│    │    └─Conv1d: 3-17                 [1, 256, 250]             16,384\n",
      "│    │    └─BatchNorm1d: 3-18            [1, 256, 250]             512\n",
      "│    │    └─ReLU: 3-19                   [1, 256, 250]             --\n",
      "│    └─Bottleneck: 2-3                   [1, 256, 250]             --\n",
      "│    │    └─Conv1d: 3-20                 [1, 64, 250]              16,384\n",
      "│    │    └─ReLU: 3-21                   [1, 64, 250]              --\n",
      "│    │    └─BatchNorm1d: 3-22            [1, 64, 250]              128\n",
      "│    │    └─Conv1d: 3-23                 [1, 64, 250]              12,288\n",
      "│    │    └─ReLU: 3-24                   [1, 64, 250]              --\n",
      "│    │    └─BatchNorm1d: 3-25            [1, 64, 250]              128\n",
      "│    │    └─Conv1d: 3-26                 [1, 256, 250]             16,384\n",
      "│    │    └─BatchNorm1d: 3-27            [1, 256, 250]             512\n",
      "│    │    └─ReLU: 3-28                   [1, 256, 250]             --\n",
      "├─Sequential: 1-6                        [1, 512, 125]             --\n",
      "│    └─Bottleneck: 2-4                   [1, 512, 125]             --\n",
      "│    │    └─Conv1d: 3-29                 [1, 128, 250]             32,768\n",
      "│    │    └─ReLU: 3-30                   [1, 128, 250]             --\n",
      "│    │    └─BatchNorm1d: 3-31            [1, 128, 250]             256\n",
      "│    │    └─Conv1d: 3-32                 [1, 128, 125]             49,152\n",
      "│    │    └─ReLU: 3-33                   [1, 128, 125]             --\n",
      "│    │    └─BatchNorm1d: 3-34            [1, 128, 125]             256\n",
      "│    │    └─Conv1d: 3-35                 [1, 512, 125]             65,536\n",
      "│    │    └─BatchNorm1d: 3-36            [1, 512, 125]             1,024\n",
      "│    │    └─Sequential: 3-37             [1, 512, 125]             132,096\n",
      "│    │    └─ReLU: 3-38                   [1, 512, 125]             --\n",
      "│    └─Bottleneck: 2-5                   [1, 512, 125]             --\n",
      "│    │    └─Conv1d: 3-39                 [1, 128, 125]             65,536\n",
      "│    │    └─ReLU: 3-40                   [1, 128, 125]             --\n",
      "│    │    └─BatchNorm1d: 3-41            [1, 128, 125]             256\n",
      "│    │    └─Conv1d: 3-42                 [1, 128, 125]             49,152\n",
      "│    │    └─ReLU: 3-43                   [1, 128, 125]             --\n",
      "│    │    └─BatchNorm1d: 3-44            [1, 128, 125]             256\n",
      "│    │    └─Conv1d: 3-45                 [1, 512, 125]             65,536\n",
      "│    │    └─BatchNorm1d: 3-46            [1, 512, 125]             1,024\n",
      "│    │    └─ReLU: 3-47                   [1, 512, 125]             --\n",
      "│    └─Bottleneck: 2-6                   [1, 512, 125]             --\n",
      "│    │    └─Conv1d: 3-48                 [1, 128, 125]             65,536\n",
      "│    │    └─ReLU: 3-49                   [1, 128, 125]             --\n",
      "│    │    └─BatchNorm1d: 3-50            [1, 128, 125]             256\n",
      "│    │    └─Conv1d: 3-51                 [1, 128, 125]             49,152\n",
      "│    │    └─ReLU: 3-52                   [1, 128, 125]             --\n",
      "│    │    └─BatchNorm1d: 3-53            [1, 128, 125]             256\n",
      "│    │    └─Conv1d: 3-54                 [1, 512, 125]             65,536\n",
      "│    │    └─BatchNorm1d: 3-55            [1, 512, 125]             1,024\n",
      "│    │    └─ReLU: 3-56                   [1, 512, 125]             --\n",
      "│    └─Bottleneck: 2-7                   [1, 512, 125]             --\n",
      "│    │    └─Conv1d: 3-57                 [1, 128, 125]             65,536\n",
      "│    │    └─ReLU: 3-58                   [1, 128, 125]             --\n",
      "│    │    └─BatchNorm1d: 3-59            [1, 128, 125]             256\n",
      "│    │    └─Conv1d: 3-60                 [1, 128, 125]             49,152\n",
      "│    │    └─ReLU: 3-61                   [1, 128, 125]             --\n",
      "│    │    └─BatchNorm1d: 3-62            [1, 128, 125]             256\n",
      "│    │    └─Conv1d: 3-63                 [1, 512, 125]             65,536\n",
      "│    │    └─BatchNorm1d: 3-64            [1, 512, 125]             1,024\n",
      "│    │    └─ReLU: 3-65                   [1, 512, 125]             --\n",
      "├─Sequential: 1-7                        [1, 1024, 63]             --\n",
      "│    └─Bottleneck: 2-8                   [1, 1024, 63]             --\n",
      "│    │    └─Conv1d: 3-66                 [1, 256, 125]             131,072\n",
      "│    │    └─ReLU: 3-67                   [1, 256, 125]             --\n",
      "│    │    └─BatchNorm1d: 3-68            [1, 256, 125]             512\n",
      "│    │    └─Conv1d: 3-69                 [1, 256, 63]              196,608\n",
      "│    │    └─ReLU: 3-70                   [1, 256, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-71            [1, 256, 63]              512\n",
      "│    │    └─Conv1d: 3-72                 [1, 1024, 63]             262,144\n",
      "│    │    └─BatchNorm1d: 3-73            [1, 1024, 63]             2,048\n",
      "│    │    └─Sequential: 3-74             [1, 1024, 63]             526,336\n",
      "│    │    └─ReLU: 3-75                   [1, 1024, 63]             --\n",
      "│    └─Bottleneck: 2-9                   [1, 1024, 63]             --\n",
      "│    │    └─Conv1d: 3-76                 [1, 256, 63]              262,144\n",
      "│    │    └─ReLU: 3-77                   [1, 256, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-78            [1, 256, 63]              512\n",
      "│    │    └─Conv1d: 3-79                 [1, 256, 63]              196,608\n",
      "│    │    └─ReLU: 3-80                   [1, 256, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-81            [1, 256, 63]              512\n",
      "│    │    └─Conv1d: 3-82                 [1, 1024, 63]             262,144\n",
      "│    │    └─BatchNorm1d: 3-83            [1, 1024, 63]             2,048\n",
      "│    │    └─ReLU: 3-84                   [1, 1024, 63]             --\n",
      "│    └─Bottleneck: 2-10                  [1, 1024, 63]             --\n",
      "│    │    └─Conv1d: 3-85                 [1, 256, 63]              262,144\n",
      "│    │    └─ReLU: 3-86                   [1, 256, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-87            [1, 256, 63]              512\n",
      "│    │    └─Conv1d: 3-88                 [1, 256, 63]              196,608\n",
      "│    │    └─ReLU: 3-89                   [1, 256, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-90            [1, 256, 63]              512\n",
      "│    │    └─Conv1d: 3-91                 [1, 1024, 63]             262,144\n",
      "│    │    └─BatchNorm1d: 3-92            [1, 1024, 63]             2,048\n",
      "│    │    └─ReLU: 3-93                   [1, 1024, 63]             --\n",
      "│    └─Bottleneck: 2-11                  [1, 1024, 63]             --\n",
      "│    │    └─Conv1d: 3-94                 [1, 256, 63]              262,144\n",
      "│    │    └─ReLU: 3-95                   [1, 256, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-96            [1, 256, 63]              512\n",
      "│    │    └─Conv1d: 3-97                 [1, 256, 63]              196,608\n",
      "│    │    └─ReLU: 3-98                   [1, 256, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-99            [1, 256, 63]              512\n",
      "│    │    └─Conv1d: 3-100                [1, 1024, 63]             262,144\n",
      "│    │    └─BatchNorm1d: 3-101           [1, 1024, 63]             2,048\n",
      "│    │    └─ReLU: 3-102                  [1, 1024, 63]             --\n",
      "│    └─Bottleneck: 2-12                  [1, 1024, 63]             --\n",
      "│    │    └─Conv1d: 3-103                [1, 256, 63]              262,144\n",
      "│    │    └─ReLU: 3-104                  [1, 256, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-105           [1, 256, 63]              512\n",
      "│    │    └─Conv1d: 3-106                [1, 256, 63]              196,608\n",
      "│    │    └─ReLU: 3-107                  [1, 256, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-108           [1, 256, 63]              512\n",
      "│    │    └─Conv1d: 3-109                [1, 1024, 63]             262,144\n",
      "│    │    └─BatchNorm1d: 3-110           [1, 1024, 63]             2,048\n",
      "│    │    └─ReLU: 3-111                  [1, 1024, 63]             --\n",
      "│    └─Bottleneck: 2-13                  [1, 1024, 63]             --\n",
      "│    │    └─Conv1d: 3-112                [1, 256, 63]              262,144\n",
      "│    │    └─ReLU: 3-113                  [1, 256, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-114           [1, 256, 63]              512\n",
      "│    │    └─Conv1d: 3-115                [1, 256, 63]              196,608\n",
      "│    │    └─ReLU: 3-116                  [1, 256, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-117           [1, 256, 63]              512\n",
      "│    │    └─Conv1d: 3-118                [1, 1024, 63]             262,144\n",
      "│    │    └─BatchNorm1d: 3-119           [1, 1024, 63]             2,048\n",
      "│    │    └─ReLU: 3-120                  [1, 1024, 63]             --\n",
      "│    └─Bottleneck: 2-14                  [1, 1024, 63]             --\n",
      "│    │    └─Conv1d: 3-121                [1, 256, 63]              262,144\n",
      "│    │    └─ReLU: 3-122                  [1, 256, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-123           [1, 256, 63]              512\n",
      "│    │    └─Conv1d: 3-124                [1, 256, 63]              196,608\n",
      "│    │    └─ReLU: 3-125                  [1, 256, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-126           [1, 256, 63]              512\n",
      "│    │    └─Conv1d: 3-127                [1, 1024, 63]             262,144\n",
      "│    │    └─BatchNorm1d: 3-128           [1, 1024, 63]             2,048\n",
      "│    │    └─ReLU: 3-129                  [1, 1024, 63]             --\n",
      "│    └─Bottleneck: 2-15                  [1, 1024, 63]             --\n",
      "│    │    └─Conv1d: 3-130                [1, 256, 63]              262,144\n",
      "│    │    └─ReLU: 3-131                  [1, 256, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-132           [1, 256, 63]              512\n",
      "│    │    └─Conv1d: 3-133                [1, 256, 63]              196,608\n",
      "│    │    └─ReLU: 3-134                  [1, 256, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-135           [1, 256, 63]              512\n",
      "│    │    └─Conv1d: 3-136                [1, 1024, 63]             262,144\n",
      "│    │    └─BatchNorm1d: 3-137           [1, 1024, 63]             2,048\n",
      "│    │    └─ReLU: 3-138                  [1, 1024, 63]             --\n",
      "│    └─Bottleneck: 2-16                  [1, 1024, 63]             --\n",
      "│    │    └─Conv1d: 3-139                [1, 256, 63]              262,144\n",
      "│    │    └─ReLU: 3-140                  [1, 256, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-141           [1, 256, 63]              512\n",
      "│    │    └─Conv1d: 3-142                [1, 256, 63]              196,608\n",
      "│    │    └─ReLU: 3-143                  [1, 256, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-144           [1, 256, 63]              512\n",
      "│    │    └─Conv1d: 3-145                [1, 1024, 63]             262,144\n",
      "│    │    └─BatchNorm1d: 3-146           [1, 1024, 63]             2,048\n",
      "│    │    └─ReLU: 3-147                  [1, 1024, 63]             --\n",
      "│    └─Bottleneck: 2-17                  [1, 1024, 63]             --\n",
      "│    │    └─Conv1d: 3-148                [1, 256, 63]              262,144\n",
      "│    │    └─ReLU: 3-149                  [1, 256, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-150           [1, 256, 63]              512\n",
      "│    │    └─Conv1d: 3-151                [1, 256, 63]              196,608\n",
      "│    │    └─ReLU: 3-152                  [1, 256, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-153           [1, 256, 63]              512\n",
      "│    │    └─Conv1d: 3-154                [1, 1024, 63]             262,144\n",
      "│    │    └─BatchNorm1d: 3-155           [1, 1024, 63]             2,048\n",
      "│    │    └─ReLU: 3-156                  [1, 1024, 63]             --\n",
      "│    └─Bottleneck: 2-18                  [1, 1024, 63]             --\n",
      "│    │    └─Conv1d: 3-157                [1, 256, 63]              262,144\n",
      "│    │    └─ReLU: 3-158                  [1, 256, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-159           [1, 256, 63]              512\n",
      "│    │    └─Conv1d: 3-160                [1, 256, 63]              196,608\n",
      "│    │    └─ReLU: 3-161                  [1, 256, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-162           [1, 256, 63]              512\n",
      "│    │    └─Conv1d: 3-163                [1, 1024, 63]             262,144\n",
      "│    │    └─BatchNorm1d: 3-164           [1, 1024, 63]             2,048\n",
      "│    │    └─ReLU: 3-165                  [1, 1024, 63]             --\n",
      "│    └─Bottleneck: 2-19                  [1, 1024, 63]             --\n",
      "│    │    └─Conv1d: 3-166                [1, 256, 63]              262,144\n",
      "│    │    └─ReLU: 3-167                  [1, 256, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-168           [1, 256, 63]              512\n",
      "│    │    └─Conv1d: 3-169                [1, 256, 63]              196,608\n",
      "│    │    └─ReLU: 3-170                  [1, 256, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-171           [1, 256, 63]              512\n",
      "│    │    └─Conv1d: 3-172                [1, 1024, 63]             262,144\n",
      "│    │    └─BatchNorm1d: 3-173           [1, 1024, 63]             2,048\n",
      "│    │    └─ReLU: 3-174                  [1, 1024, 63]             --\n",
      "│    └─Bottleneck: 2-20                  [1, 1024, 63]             --\n",
      "│    │    └─Conv1d: 3-175                [1, 256, 63]              262,144\n",
      "│    │    └─ReLU: 3-176                  [1, 256, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-177           [1, 256, 63]              512\n",
      "│    │    └─Conv1d: 3-178                [1, 256, 63]              196,608\n",
      "│    │    └─ReLU: 3-179                  [1, 256, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-180           [1, 256, 63]              512\n",
      "│    │    └─Conv1d: 3-181                [1, 1024, 63]             262,144\n",
      "│    │    └─BatchNorm1d: 3-182           [1, 1024, 63]             2,048\n",
      "│    │    └─ReLU: 3-183                  [1, 1024, 63]             --\n",
      "│    └─Bottleneck: 2-21                  [1, 1024, 63]             --\n",
      "│    │    └─Conv1d: 3-184                [1, 256, 63]              262,144\n",
      "│    │    └─ReLU: 3-185                  [1, 256, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-186           [1, 256, 63]              512\n",
      "│    │    └─Conv1d: 3-187                [1, 256, 63]              196,608\n",
      "│    │    └─ReLU: 3-188                  [1, 256, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-189           [1, 256, 63]              512\n",
      "│    │    └─Conv1d: 3-190                [1, 1024, 63]             262,144\n",
      "│    │    └─BatchNorm1d: 3-191           [1, 1024, 63]             2,048\n",
      "│    │    └─ReLU: 3-192                  [1, 1024, 63]             --\n",
      "│    └─Bottleneck: 2-22                  [1, 1024, 63]             --\n",
      "│    │    └─Conv1d: 3-193                [1, 256, 63]              262,144\n",
      "│    │    └─ReLU: 3-194                  [1, 256, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-195           [1, 256, 63]              512\n",
      "│    │    └─Conv1d: 3-196                [1, 256, 63]              196,608\n",
      "│    │    └─ReLU: 3-197                  [1, 256, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-198           [1, 256, 63]              512\n",
      "│    │    └─Conv1d: 3-199                [1, 1024, 63]             262,144\n",
      "│    │    └─BatchNorm1d: 3-200           [1, 1024, 63]             2,048\n",
      "│    │    └─ReLU: 3-201                  [1, 1024, 63]             --\n",
      "│    └─Bottleneck: 2-23                  [1, 1024, 63]             --\n",
      "│    │    └─Conv1d: 3-202                [1, 256, 63]              262,144\n",
      "│    │    └─ReLU: 3-203                  [1, 256, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-204           [1, 256, 63]              512\n",
      "│    │    └─Conv1d: 3-205                [1, 256, 63]              196,608\n",
      "│    │    └─ReLU: 3-206                  [1, 256, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-207           [1, 256, 63]              512\n",
      "│    │    └─Conv1d: 3-208                [1, 1024, 63]             262,144\n",
      "│    │    └─BatchNorm1d: 3-209           [1, 1024, 63]             2,048\n",
      "│    │    └─ReLU: 3-210                  [1, 1024, 63]             --\n",
      "│    └─Bottleneck: 2-24                  [1, 1024, 63]             --\n",
      "│    │    └─Conv1d: 3-211                [1, 256, 63]              262,144\n",
      "│    │    └─ReLU: 3-212                  [1, 256, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-213           [1, 256, 63]              512\n",
      "│    │    └─Conv1d: 3-214                [1, 256, 63]              196,608\n",
      "│    │    └─ReLU: 3-215                  [1, 256, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-216           [1, 256, 63]              512\n",
      "│    │    └─Conv1d: 3-217                [1, 1024, 63]             262,144\n",
      "│    │    └─BatchNorm1d: 3-218           [1, 1024, 63]             2,048\n",
      "│    │    └─ReLU: 3-219                  [1, 1024, 63]             --\n",
      "│    └─Bottleneck: 2-25                  [1, 1024, 63]             --\n",
      "│    │    └─Conv1d: 3-220                [1, 256, 63]              262,144\n",
      "│    │    └─ReLU: 3-221                  [1, 256, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-222           [1, 256, 63]              512\n",
      "│    │    └─Conv1d: 3-223                [1, 256, 63]              196,608\n",
      "│    │    └─ReLU: 3-224                  [1, 256, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-225           [1, 256, 63]              512\n",
      "│    │    └─Conv1d: 3-226                [1, 1024, 63]             262,144\n",
      "│    │    └─BatchNorm1d: 3-227           [1, 1024, 63]             2,048\n",
      "│    │    └─ReLU: 3-228                  [1, 1024, 63]             --\n",
      "│    └─Bottleneck: 2-26                  [1, 1024, 63]             --\n",
      "│    │    └─Conv1d: 3-229                [1, 256, 63]              262,144\n",
      "│    │    └─ReLU: 3-230                  [1, 256, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-231           [1, 256, 63]              512\n",
      "│    │    └─Conv1d: 3-232                [1, 256, 63]              196,608\n",
      "│    │    └─ReLU: 3-233                  [1, 256, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-234           [1, 256, 63]              512\n",
      "│    │    └─Conv1d: 3-235                [1, 1024, 63]             262,144\n",
      "│    │    └─BatchNorm1d: 3-236           [1, 1024, 63]             2,048\n",
      "│    │    └─ReLU: 3-237                  [1, 1024, 63]             --\n",
      "│    └─Bottleneck: 2-27                  [1, 1024, 63]             --\n",
      "│    │    └─Conv1d: 3-238                [1, 256, 63]              262,144\n",
      "│    │    └─ReLU: 3-239                  [1, 256, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-240           [1, 256, 63]              512\n",
      "│    │    └─Conv1d: 3-241                [1, 256, 63]              196,608\n",
      "│    │    └─ReLU: 3-242                  [1, 256, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-243           [1, 256, 63]              512\n",
      "│    │    └─Conv1d: 3-244                [1, 1024, 63]             262,144\n",
      "│    │    └─BatchNorm1d: 3-245           [1, 1024, 63]             2,048\n",
      "│    │    └─ReLU: 3-246                  [1, 1024, 63]             --\n",
      "│    └─Bottleneck: 2-28                  [1, 1024, 63]             --\n",
      "│    │    └─Conv1d: 3-247                [1, 256, 63]              262,144\n",
      "│    │    └─ReLU: 3-248                  [1, 256, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-249           [1, 256, 63]              512\n",
      "│    │    └─Conv1d: 3-250                [1, 256, 63]              196,608\n",
      "│    │    └─ReLU: 3-251                  [1, 256, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-252           [1, 256, 63]              512\n",
      "│    │    └─Conv1d: 3-253                [1, 1024, 63]             262,144\n",
      "│    │    └─BatchNorm1d: 3-254           [1, 1024, 63]             2,048\n",
      "│    │    └─ReLU: 3-255                  [1, 1024, 63]             --\n",
      "│    └─Bottleneck: 2-29                  [1, 1024, 63]             --\n",
      "│    │    └─Conv1d: 3-256                [1, 256, 63]              262,144\n",
      "│    │    └─ReLU: 3-257                  [1, 256, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-258           [1, 256, 63]              512\n",
      "│    │    └─Conv1d: 3-259                [1, 256, 63]              196,608\n",
      "│    │    └─ReLU: 3-260                  [1, 256, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-261           [1, 256, 63]              512\n",
      "│    │    └─Conv1d: 3-262                [1, 1024, 63]             262,144\n",
      "│    │    └─BatchNorm1d: 3-263           [1, 1024, 63]             2,048\n",
      "│    │    └─ReLU: 3-264                  [1, 1024, 63]             --\n",
      "│    └─Bottleneck: 2-30                  [1, 1024, 63]             --\n",
      "│    │    └─Conv1d: 3-265                [1, 256, 63]              262,144\n",
      "│    │    └─ReLU: 3-266                  [1, 256, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-267           [1, 256, 63]              512\n",
      "│    │    └─Conv1d: 3-268                [1, 256, 63]              196,608\n",
      "│    │    └─ReLU: 3-269                  [1, 256, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-270           [1, 256, 63]              512\n",
      "│    │    └─Conv1d: 3-271                [1, 1024, 63]             262,144\n",
      "│    │    └─BatchNorm1d: 3-272           [1, 1024, 63]             2,048\n",
      "│    │    └─ReLU: 3-273                  [1, 1024, 63]             --\n",
      "├─Sequential: 1-8                        [1, 2048, 32]             --\n",
      "│    └─Bottleneck: 2-31                  [1, 2048, 32]             --\n",
      "│    │    └─Conv1d: 3-274                [1, 512, 63]              524,288\n",
      "│    │    └─ReLU: 3-275                  [1, 512, 63]              --\n",
      "│    │    └─BatchNorm1d: 3-276           [1, 512, 63]              1,024\n",
      "│    │    └─Conv1d: 3-277                [1, 512, 32]              786,432\n",
      "│    │    └─ReLU: 3-278                  [1, 512, 32]              --\n",
      "│    │    └─BatchNorm1d: 3-279           [1, 512, 32]              1,024\n",
      "│    │    └─Conv1d: 3-280                [1, 2048, 32]             1,048,576\n",
      "│    │    └─BatchNorm1d: 3-281           [1, 2048, 32]             4,096\n",
      "│    │    └─Sequential: 3-282            [1, 2048, 32]             2,101,248\n",
      "│    │    └─ReLU: 3-283                  [1, 2048, 32]             --\n",
      "│    └─Bottleneck: 2-32                  [1, 2048, 32]             --\n",
      "│    │    └─Conv1d: 3-284                [1, 512, 32]              1,048,576\n",
      "│    │    └─ReLU: 3-285                  [1, 512, 32]              --\n",
      "│    │    └─BatchNorm1d: 3-286           [1, 512, 32]              1,024\n",
      "│    │    └─Conv1d: 3-287                [1, 512, 32]              786,432\n",
      "│    │    └─ReLU: 3-288                  [1, 512, 32]              --\n",
      "│    │    └─BatchNorm1d: 3-289           [1, 512, 32]              1,024\n",
      "│    │    └─Conv1d: 3-290                [1, 2048, 32]             1,048,576\n",
      "│    │    └─BatchNorm1d: 3-291           [1, 2048, 32]             4,096\n",
      "│    │    └─ReLU: 3-292                  [1, 2048, 32]             --\n",
      "│    └─Bottleneck: 2-33                  [1, 2048, 32]             --\n",
      "│    │    └─Conv1d: 3-293                [1, 512, 32]              1,048,576\n",
      "│    │    └─ReLU: 3-294                  [1, 512, 32]              --\n",
      "│    │    └─BatchNorm1d: 3-295           [1, 512, 32]              1,024\n",
      "│    │    └─Conv1d: 3-296                [1, 512, 32]              786,432\n",
      "│    │    └─ReLU: 3-297                  [1, 512, 32]              --\n",
      "│    │    └─BatchNorm1d: 3-298           [1, 512, 32]              1,024\n",
      "│    │    └─Conv1d: 3-299                [1, 2048, 32]             1,048,576\n",
      "│    │    └─BatchNorm1d: 3-300           [1, 2048, 32]             4,096\n",
      "│    │    └─ReLU: 3-301                  [1, 2048, 32]             --\n",
      "├─AdaptiveAvgPool1d: 1-9                 [1, 2048, 1]              --\n",
      "├─Linear: 1-10                           [1, 19]                   38,931\n",
      "├─Sigmoid: 1-11                          [1, 19]                   --\n",
      "==========================================================================================\n",
      "Total params: 28,305,555\n",
      "Trainable params: 28,305,555\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (Units.GIGABYTES): 1.57\n",
      "==========================================================================================\n",
      "Input size (MB): 0.05\n",
      "Forward/backward pass size (MB): 56.49\n",
      "Params size (MB): 113.22\n",
      "Estimated Total Size (MB): 169.76\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "model = ResNet(Bottleneck, [3, 4, 23, 3], num_classes=19).float()\n",
    "print(summary(model.to(device), (1,12,1000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(4*1024-107.88)/107.88 #Max batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = 64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Test AUC metric\"\"\"\n",
    "ml_auroc = MultilabelAUROC(num_labels=y_train.shape[1], average=\"macro\", thresholds=None)\n",
    "# ml_auroc(model(X_train[0:10].to(device)), train_label_mapping[0:10].to(device).int())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Max Learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "epochs = 10\n",
    "model = model = ResNet(Bottleneck, [3, 4, 23, 3], num_classes=19).float()\n",
    "model = model.to(device)\n",
    "lr = 1e-6\n",
    "optimizer = optim.Adam(model.parameters(), lr = lr, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loss = []\n",
    "lrs = []\n",
    "\n",
    "while lr < 1:\n",
    "    for i, (signal, labels) in enumerate(train_loader):\n",
    "        signal = signal.to(device)\n",
    "        labels = labels.to(device)\n",
    "        output = model(signal)\n",
    "        loss = criterion(output, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        train_loss.append(loss.item())\n",
    "        lrs.append(lr)\n",
    "        lr *= 1.1\n",
    "\n",
    "        for g in optimizer.param_groups:\n",
    "            g['lr'] = lr \n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        if i > 200 or lr > 1:\n",
    "            break\n",
    "\n",
    "lrs = np.array(lrs)\n",
    "train_loss = np.array(train_loss)\n",
    "\n",
    "lr_max = lrs[np.where(train_loss == train_loss.min())[0]]\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(lrs, train_loss)\n",
    "plt.plot(lr_max, train_loss[lrs == lr_max], '.r')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.02400691612424e-05"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "fig = plt.figure()\n",
    "plt.plot(lrs, train_loss)\n",
    "plt.plot(lr_max, train_loss[lrs == lr_max], '.r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_max = 0.135/10\n",
    "lr = lr_max\n",
    "epochs = 10\n",
    "criterion = nn.BCELoss()\n",
    "epochs = 10\n",
    "model = model = ResNet(Bottleneck, [3, 4, 23, 3], num_classes=19).float()\n",
    "model = model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr = lr, weight_decay=1e-4)\n",
    "\n",
    "for g in optimizer.param_groups:\n",
    "    g['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs = []\n",
    "t = 0\n",
    "steps_per_epoch = len(train_loader)\n",
    "T_max = steps_per_epoch*epochs\n",
    "T_0 = T_max/5 \n",
    "for t in range(T_max):\n",
    "    if t <= T_0:\n",
    "        lr = 10**(-4) + (t/T_0)*lr_max  \n",
    "    else: \n",
    "        lr = lr_max*np.cos((np.pi/2)*((t-T_0)/(T_max-T_0))) + 10**(-6)\n",
    "    lrs.append(lr)\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(lrs)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr =lr_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0\n",
    "steps_per_epoch = len(train_loader)\n",
    "T_max = steps_per_epoch*epochs\n",
    "T_0 = T_max/5 \n",
    "learning_rates = []\n",
    "train_losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i, (signal, labels) in enumerate(train_loader):\n",
    "        signal = signal.to(device); labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(signal)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
    "        if t <= T_0:\n",
    "            lr = 10**(-4) + (t/T_0)*lr_max  \n",
    "        else: \n",
    "            lr = lr_max*np.cos((np.pi/2)*((t-T_0)/(T_max-T_0))) + 10**(-6) \n",
    "\n",
    "        for g in optimizer.param_groups:\n",
    "            g['lr'] = lr \n",
    "        learning_rates.append(lr)\n",
    "        train_losses.append(loss.item())\n",
    "        optimizer.step()\n",
    "        t+=1\n",
    "        \n",
    "        train_AUC = ml_auroc(outputs, labels.int())\n",
    "        writer.add_scalar(\"Train_Loss\", loss, t)\n",
    "        writer.add_scalar(\"Learning rate\", lr, t)\n",
    "        writer.add_scalar(\"Batch Train AUC\", train_AUC, t)\n",
    "\n",
    "        if i%100 == 0:\n",
    "            print(f\"Step: {i+1}/{len(train_loader)}  |  Train loss: {loss.item():.4f}  |  Train AUC: {train_AUC:.4f}\")\n",
    "           \n",
    "\n",
    "    # model.eval()\n",
    "    test_auc = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (signal, labels) in enumerate(test_loader):\n",
    "            signal = signal.to(device); labels = labels.to(device)\n",
    "            outputs = model(signal)\n",
    "            test_auc += ml_auroc(outputs, labels.int())\n",
    "        test_auc /= len(test_loader)\n",
    "    writer.add_scalar(\"Test AUC\", test_auc, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_Auc = 0\n",
    "with torch.no_grad():\n",
    "    for i, (signal, labels) in enumerate(test_loader):\n",
    "        signal = signal.to(device); labels = labels.to(device)\n",
    "        outputs = model(signal)\n",
    "        test_Auc += ml_auroc(outputs, labels.int())\n",
    "\n",
    "test_Auc /= len(test_loader)\n",
    "test_Auc\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('resnet101_model.pickle', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, max_len=1000, emb_size=12):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "\n",
    "        pe = torch.zeros(max_len, emb_size)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, emb_size, 2).float() * (-np.log(10000.0) / emb_size))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:x.size(0), :]\n",
    "\n",
    "class Transformer(nn.Transformer):\n",
    "    def __init__(self, emb_size=12, nhead=6, depth=6, hidden_size=128, seq_length=1000, num_classes=5):\n",
    "        super(Transformer, self).__init__(d_model=emb_size, nhead=nhead, num_encoder_layers=depth, num_decoder_layers=depth, dim_feedforward=hidden_size)\n",
    "    \n",
    "        self.pos_encoder = PositionalEncoding(seq_length, emb_size)\n",
    "        self.decoder = nn.Linear(emb_size, 256)\n",
    "        self.linear1 = nn.Linear(256, 512)\n",
    "        self.linear2 = nn.Linear(512, 1024)\n",
    "        self.linear3 = nn.Linear(1024, num_classes)\n",
    "        \n",
    "    def __forward_impl(self, x):\n",
    "        #x = self.pos_encoder(x)\n",
    "        x = self.encoder(x)\n",
    "        x = x.mean(dim=1)\n",
    "        x = self.decoder(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.linear1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.linear3(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.__forward_impl(x)\n",
    "    \n",
    "model = Transformer(nhead=6, hidden_size=512, depth=3).to(device)\n",
    "\n",
    "model(X_train[0].T.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0].T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer(nhead=6, hidden_size=512, depth=3).to(device)\n",
    "print(summary(model, [1000, 12]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model.to(device), (1,1000, 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "512*1024+512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Transformer needs X input as (seq_len, batch_size, channels)\"\"\"\n",
    "model = Transformer(nhead=6, hidden_size=512, depth=3).to(device)\n",
    "# resnetModel = ResNet(Bottleneck, [3, 4, 23, 3], num_classes=6).to(device)\n",
    "\n",
    "# resnetModel(X_train[0:1].to(device))\n",
    "print(\"Forward pass\")\n",
    "X_train = X_train.transpose(0,1).transpose(0,2)\n",
    "model(X_train[:, :17, :].to(device))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
