### Convexity

```
Go to ML Convexity Notes. Redo the proofs. 
```

#### Intro to GD
 - Convergence of iterates to $w^*$
 - Convergernce of the optimal loss $l(w^*)$


 ```
 Lookup Brendt's algorithm
 Numerical Recipes in C - lookup the book
 ```
 Newton's method converts the skewed gradient elliopsoid into spherical gradients. 
 If you find yourself solving a low dimensional problem(500-1000) parameters, use Newton's method. 

 #### Convergence rate for gradient descent

